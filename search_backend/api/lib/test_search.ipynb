{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f033bbf1b10c19fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b27fb4c96a5f195",
   "metadata": {},
   "source": [
    "# Test search functions\n",
    "\n",
    "To install necessary packages, run `pip install -e '.[search_backend, dev]'`.\n",
    "\n",
    "Before running this notebook, set up an Opensearch container following instructions here: https://docs.haystack.deepset.ai/v2.0/docs/opensearchbm25retriever\n",
    "\n",
    "Or alternatively open Docker desktop and run:\n",
    "```\n",
    "docker pull opensearchproject/opensearch:2.11.0\n",
    "docker run -p 9200:9200 -p 9600:9600 -e \"discovery.type=single-node\" -e \"OPENSEARCH_JAVA_OPTS=-Xms1024m -Xmx1024m\" opensearchproject/opensearch:2.11.0\n",
    "```\n",
    "\n",
    "Hybrid search was introduced in OpenSearch v2.11. Not clear whether Haystack is able to properly use a version this recent. Proper hybrid search with OpenSearch hasn't been enabled yet in Haystack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8dcb5e192b034",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# os.chdir('~/rd-search-backend')\n",
    "\n",
    "from search_backend.api.lib.config import get_config\n",
    "from search_backend.api.lib.services import SERVICES\n",
    "from search_backend.api.lib.opensearchpipeline import run_indexing_pipeline, RetrievalPipeline\n",
    "from search_backend.api.lib.searchfunctions import bm25_search, semantic_search, hybrid_search, pretty_print_results\n",
    "\n",
    "cfg = get_config()\n",
    "\n",
    "test_query = \"short custody\"\n",
    "\n",
    "print(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5de3378dad0a3b",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2dc277da6bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ai_catalogue.json') as f:\n",
    "    project_list = json.load(f)\n",
    "\n",
    "print(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f054d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace newlines as they interfere with the matching\n",
    "project_list = [{k : v.replace('\\n', ' ') if v is not None else v for k, v in project.items()} for project in project_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0648631",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_search = [\n",
    "    'project_name',\n",
    "    'description',\n",
    "    'what_does_this_initiative_do',\n",
    "    'reasons_for_use',\n",
    "    'problem_solved_by_the_initiative',\n",
    "    'metrics_or_intended_impacts'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a903ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_doc_dict(doc: dict, field: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Reformat data into format accepted by Haystack.\n",
    "    Here we wish to search over multiple fields, so we include the text from different\n",
    "    fields in separate dictionaries within a list.\n",
    "\n",
    "    :doc: dictionary containing text data to search along with accompanying metadata\n",
    "    :field: string corresponding to one of the dictionary keys, to indicate the field to index the text from\n",
    "    \"\"\"\n",
    "\n",
    "    content = doc[field]\n",
    "    # doc.pop(field)\n",
    "\n",
    "    if content is None:\n",
    "        # We can't index None values, so returning None here allows us to skip fields where no info is provided\n",
    "        return None\n",
    "    else:\n",
    "        meta = doc.copy()\n",
    "        meta['matched_field'] = field\n",
    "\n",
    "        dict = {\n",
    "            'meta': meta,\n",
    "            'content': content,\n",
    "        }\n",
    "\n",
    "        return dict\n",
    "\n",
    "\n",
    "dataset = [y for project in project_list[:3] for field in fields_to_search if (y := format_doc_dict(project, field)) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928098f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37631d01d46a31d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T10:43:45.255542Z",
     "start_time": "2024-10-01T10:43:45.177978Z"
    }
   },
   "source": [
    "## Set up Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f125e77bc8ff4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an existing Opensearch document store\n",
    "# query_document_store = SERVICES[\"querydocumentstore\"]\n",
    "from haystack_integrations.document_stores.opensearch import OpenSearchDocumentStore\n",
    "query_document_store = OpenSearchDocumentStore(\n",
    "    hosts=\"http://localhost:9200\",\n",
    "    use_ssl=True,\n",
    "    verify_certs=False,\n",
    "    http_auth=(\"admin\", \"admin\"),\n",
    "    embedding_dim=384,\n",
    "    recreate_index=True,\n",
    "    index=\"document\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae545f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_indexing_pipeline(dataset, query_document_store, cfg, semantic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d7e6b36113129",
   "metadata": {},
   "source": [
    "## Run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28960f28d2f72672",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_pipeline = RetrievalPipeline(query_document_store)\n",
    "bm25_pipeline = bm25_pipeline.setup_bm25_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"improved service quality\"\n",
    "results = bm25_search(test_query, bm25_pipeline, top_k=3)\n",
    "pretty_print_results(results[\"bm25_retriever\"]['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"bm25_retriever\"]['documents'][0].meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Search backend",
   "language": "python",
   "name": "venv_search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
