{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Demo search backend\n",
    "\n",
    "The notebook demos basic search functionality using OpenSearch and the Haystack framework. You must have Docker Desktop installed and be a part of the [MoJ Docker org](https://user-guide.operations-engineering.service.justice.gov.uk/documentation/services/dockerhub.html#docker) (so that you're covered by a licence) prior to using OpenSearch.\n",
    "\n",
    "To install necessary packages, run `pip install -e '.[search_backend, dev]'`.\n",
    "\n",
    "Before running this notebook, set up an Opensearch container (see docker-compose.yml) by running:\n",
    "```\n",
    "docker compose up localstack\n",
    "```\n",
    "Or alternatively follow instructions here: https://docs.haystack.deepset.ai/v2.0/docs/opensearchbm25retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from haystack import Document\n",
    "from haystack_integrations.document_stores.opensearch import OpenSearchDocumentStore\n",
    "from search_backend.indexing_pipeline import IndexingPipeline\n",
    "from search_backend.retrieval_pipeline import RetrievalPipeline\n",
    "from search_backend.search import Search\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    # Optional arg for the OpenSearch docstore, to prevent trying to index everything in one go\n",
    "    \"index_batch_size\": 10,\n",
    "    # Select embedding model for the semantic search. This should be a sentence-similarity\n",
    "    # model available on Huggingface: https://huggingface.co/models?pipeline_tag=sentence-similarity\n",
    "    \"dense_embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    # The value of the embedding dimension must match that specified for the model defined above\n",
    "    \"embedding_dim\": 384,\n",
    "    # Language model used to rank search results better than the embedding retrieval can\n",
    "    \"rerank_model\": \"cross-encoder/ms-marco-MiniLM-L-2-v2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Get some text data\n",
    "\n",
    "This dataset is based on Wikipedia introductions to the Seven Wonders of the Ancient World."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../tests/data/demo_data.json') as f:\n",
    "    doc_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into Haystack Document instances\n",
    "docs = [Document(**content) for content in doc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Set up Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an existing Opensearch container - see docker-compose.yml for Opensearch settings\n",
    "query_document_store = OpenSearchDocumentStore(\n",
    "    hosts=\"http://0.0.0.0:4566/opensearch/eu-west-2/rd-demo\",\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    http_auth=(\"localstack\", \"localstack\"),\n",
    "    embedding_dim=cfg[\"embedding_dim\"],\n",
    "    batch_size=cfg[\"index_batch_size\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the documents to the vector store\n",
    "indexer = IndexingPipeline(query_document_store, dense_embedding_model=cfg[\"dense_embedding_model\"], semantic=True)\n",
    "indexer.index_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Run BM25 search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_pipeline = RetrievalPipeline(query_document_store).setup_bm25_pipeline()\n",
    "bm25_search_init = Search(bm25_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"lighthouse\"\n",
    "# test_query = \"wonder that features plants\"\n",
    "results = bm25_search_init.bm25_search(test_query, top_k=3)\n",
    "\n",
    "for doc in results:\n",
    "    print(f'{doc.meta[\"title\"]} - Score: {doc.score}')\n",
    "    print(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Run semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_pipeline = RetrievalPipeline(\n",
    "    query_document_store,\n",
    "    dense_embedding_model=cfg['dense_embedding_model'],\n",
    "    rerank_model=cfg['rerank_model']\n",
    ").setup_semantic_pipeline()\n",
    "semantic_search_init = Search(semantic_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"wonder that features plants\"\n",
    "results = semantic_search_init.semantic_search(test_query, top_k=3, threshold=0.00001)\n",
    "\n",
    "for doc in results:\n",
    "    print(f'{doc.meta[\"title\"]} - Score: {doc.score}')\n",
    "    print(doc.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_pipeline = RetrievalPipeline(\n",
    "    query_document_store,\n",
    "    dense_embedding_model=cfg['dense_embedding_model'],\n",
    "    rerank_model=cfg['rerank_model']\n",
    ").setup_hybrid_pipeline()\n",
    "hybrid_search_init = Search(hybrid_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"wonder that features plants\"\n",
    "results = hybrid_search_init.hybrid_search(test_query, bm25_top_k=3, semantic_top_k=3, threshold=0.000001)\n",
    "\n",
    "for doc in results:\n",
    "    print(f'{doc.meta[\"title\"]} - Score: {doc.score}')\n",
    "    print(doc.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
