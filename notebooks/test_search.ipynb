{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Test search functions\n",
    "\n",
    "The notebook demos basic search functionality using OpenSearch and the Haystack framework. You must have Docker Desktop installed and be a part of the [MoJ Docker org](https://user-guide.operations-engineering.service.justice.gov.uk/documentation/services/dockerhub.html#docker) (so that you're covered by a licence) prior to using OpenSearch.\n",
    "\n",
    "To install necessary packages, run `pip install -e '.[search_backend, dev]'`.\n",
    "\n",
    "Before running this notebook, set up an Opensearch container (see docker-compose.yml) by running:\n",
    "```\n",
    "docker compose up localstack\n",
    "```\n",
    "Or alternatively follow instructions here: https://docs.haystack.deepset.ai/v2.0/docs/opensearchbm25retriever\n",
    "\n",
    "Hybrid search was introduced in OpenSearch v2.11. Not clear whether Haystack is able to properly use a version this recent. Proper hybrid search with OpenSearch hasn't been enabled yet in Haystack.\n",
    "\n",
    "You will also need the JSON file dummy-products-20241015.json. This is [kept on the wiki](https://dsdmoj.atlassian.net/wiki/spaces/AN/pages/5214503074/Dummy+data) for privacy purposes. Copy it into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from haystack import Document\n",
    "from search_backend.config import get_config\n",
    "from search_backend.indexing_pipeline import IndexingPipeline\n",
    "from search_backend.retrieval_pipeline import RetrievalPipeline\n",
    "from search_backend.search import Search\n",
    "from prep_data import replace_newlines, prep_project_data\n",
    "\n",
    "cfg = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open('dummy_data.json') as f:\n",
    "    project_list = json.load(f)\n",
    "\n",
    "print(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace newlines as they interfere with the matching\n",
    "project_list = replace_newlines(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prep_project_data(project_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Set up Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an existing Opensearch document store\n",
    "from haystack_integrations.document_stores.opensearch import OpenSearchDocumentStore\n",
    "\n",
    "query_document_store = OpenSearchDocumentStore(\n",
    "    hosts=\"http://0.0.0.0:4566/opensearch/eu-west-2/rd-demo\",\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    http_auth=(\"localstack\", \"localstack\"),\n",
    "    embedding_dim=cfg[\"embedding_dim\"],\n",
    "    recreate_index=True,\n",
    "    index=\"document\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(**content) for content in dataset]\n",
    "\n",
    "indexer = IndexingPipeline(query_document_store, dense_embedding_model=cfg[\"dense_embedding_model\"], semantic=True)\n",
    "indexer.index_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Run BM25 search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_pipeline = RetrievalPipeline(query_document_store)\n",
    "bm25_pipeline = bm25_pipeline.setup_bm25_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"rehabilitation\"\n",
    "bm25_search_init = Search(bm25_pipeline)\n",
    "results = bm25_search_init.bm25_search(test_query, top_k=3)\n",
    "\n",
    "for doc in results:\n",
    "    print('-----------------------------------')\n",
    "    print(f'{doc.meta[\"name\"]} - Score: {doc.score}')\n",
    "    print(doc.content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Run semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_pipeline = RetrievalPipeline(query_document_store, dense_embedding_model=cfg['dense_embedding_model'], rerank_model=cfg['rerank_model'])\n",
    "semantic_pipeline = semantic_pipeline.setup_semantic_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"project relating to law\"\n",
    "semantic_search_init = Search(semantic_pipeline)\n",
    "results = semantic_search_init.semantic_search(test_query, top_k=3, threshold=0.00001)\n",
    "\n",
    "for doc in results:\n",
    "    print('-----------------------------------')\n",
    "    print(f'{doc.meta[\"name\"]} - Score: {doc.score}')\n",
    "    print(doc.content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_pipeline = RetrievalPipeline(query_document_store, dense_embedding_model=cfg['dense_embedding_model'], rerank_model=cfg['rerank_model'])\n",
    "hybrid_pipeline = hybrid_pipeline.setup_hybrid_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"improved service quality\"\n",
    "hybrid_search_init = Search(hybrid_pipeline)\n",
    "results = hybrid_search_init.hybrid_search(test_query, top_k=3)\n",
    "\n",
    "for doc in results:\n",
    "    print('-----------------------------------')\n",
    "    print(f'{doc.meta[\"name\"]} - Score: {doc.score}')\n",
    "    print(doc.content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
